{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autor: Antunes Dantas\n",
    "\n",
    "O objetivo deste documento é mostrar como implementar um motor de busca que usa algoritmos de rankeamento de documentos mais eficazes como o TF, TF-IDF e o BM25.\n",
    "Primeiro, vamos importar as bibliotecas necessárias para a implementação do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, será necessário configurar o básico para a criação do índice invertido. A minha estratégia aqui foi de criar\n",
    "uma segunda estrutura de dados. Essa estrutura, chamada de TF, guardará o term frequency para cada documento. Assim, quando for preciso acessar tal valor, poderei fazer em tempo constante. Além disso será necessário ter cuidado para tratar os valores NA (valores inexistentes) para evitar erros durante a execução dos algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOME_DO_ARQUIVO = 'estadao_noticias_eleicao.csv'\n",
    "indice_invertido = dict()\n",
    "dados = pd.read_csv(NOME_DO_ARQUIVO)\n",
    "dados = dados.replace(np.nan, '', regex=True)\n",
    "tf = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a geração do índice invertido, a única mudança é que agora calcularemos o term frequency de cada termo do documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geraIndice():\n",
    "    for i, row in dados.iterrows():\n",
    "        \n",
    "        titulo = (word.lower() for word in (nltk.word_tokenize(row['titulo'])))\n",
    "        subtitulo = (word.lower() for word in (nltk.word_tokenize(row['subTitulo'])))\n",
    "        conteudo = (word.lower() for word in (nltk.word_tokenize(row['conteudo'])))\n",
    "        palavras_divididas = list(titulo) + list(subtitulo) + list(conteudo)\n",
    "        tfDoc = {}\n",
    "        for palavra in palavras_divididas:\n",
    "            if palavra not in indice_invertido:\n",
    "                indice_invertido[palavra] = set([row['idNoticia']])\n",
    "            else:\n",
    "                indice_invertido[palavra].add(row['idNoticia'])\n",
    "            if palavra not in tfDoc:\n",
    "                tfDoc[palavra] = 0\n",
    "            tfDoc[palavra] += 1\n",
    "        tf[row['idNoticia']] = tfDoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo binário consiste de uma consulta onde os documentos retornados são aqueles que contém todos os termos da busca. Não é muito eficaz, visto que não realiza nenhum rankeamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeloBinario(termos):\n",
    "    indice = []\n",
    "    for termo in termos:\n",
    "        indice.append(indice_invertido[termo])\n",
    "    return list(set.intersection(*indice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQueryTF(query):\n",
    "    tf = {}\n",
    "    for term in query:\n",
    "        if term not in tf:\n",
    "            tf[term] = 0\n",
    "        tf[term] += 1\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já o modelo TF usa o term frequency de cada termo no documento para mostrar os documentos onde o termo aparece mais. Ou seja, quanto mais vezes o termo aparece no documento e na query, mais ele será rankeado para cima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeloTF(termos):\n",
    "    documentos = modeloBinario(termos)\n",
    "    documentsTF = []\n",
    "    for idDoc in documentos:\n",
    "        documentWeight = 0\n",
    "        for termo in termos:\n",
    "            docTF = tf[idDoc][termo] if (termo in tf[idDoc]) else 0\n",
    "            qTF = termos.count(termo)\n",
    "            documentWeight += docTF * qTF\n",
    "            \n",
    "        documentsTF.append((idDoc, documentWeight))\n",
    "    documentsTF.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    ids = []\n",
    "    for tupla in documentsTF:\n",
    "        ids.append(tupla[0])\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo TF-IDF leva em conta além do term frequency do documento, a quantidade de vezes que aquele termo apareceu no documento. Assim, quando um termo aparece muitas vezes no documento, ele perde relevância. É especialmente útil para evitar que stop words tenham um poder de rankeamento grande no documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeloIDF(termos):\n",
    "    documentos = modeloBinario(termos)\n",
    "    documentsTF = []\n",
    "    for idDoc in documentos:\n",
    "        documentWeight = 0\n",
    "        for termo in termos:\n",
    "            docTF = tf[idDoc][termo] if (termo in tf[idDoc]) else 0\n",
    "            qTF = termos.count(termo)\n",
    "            idf = math.log(dados.titulo.size/len(indice_invertido[termo]))\n",
    "            documentWeight += docTF * qTF * idf\n",
    "            \n",
    "        documentsTF.append((idDoc, documentWeight))\n",
    "    documentsTF.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    ids = []\n",
    "    for tupla in documentsTF:\n",
    "        ids.append(tupla[0])\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O BM25 aprimora o TF-IDF. Ele ajuda na normalização da importância de um termo na busca, assim, a nós conseguimos controlar a curva de crescimento da importância de um termo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeloBM25(termos):\n",
    "    documentos = modeloBinario(termos)\n",
    "    documentsTF = []\n",
    "    k = 5\n",
    "    for idDoc in documentos:\n",
    "        documentWeight = 0\n",
    "        for termo in termos:\n",
    "            docTF = tf[idDoc][termo] if (termo in tf[idDoc]) else 0\n",
    "            qTF = termos.count(termo)\n",
    "            idf = math.log(dados.titulo.size/len(indice_invertido[termo]))\n",
    "            bm25 = ((k + 1)*(docTF)) / (docTF + k)\n",
    "            documentWeight += docTF * qTF * idf * bm25\n",
    "            \n",
    "        documentsTF.append((idDoc, documentWeight))\n",
    "    documentsTF.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    ids = []\n",
    "    for tupla in documentsTF:\n",
    "        ids.append(tupla[0])\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para avaliar o resultado da implementação, vamos realizar um conjunto de buscas e compará-las com um um gabarito fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['segundo turno', 'lava jato', 'projeto de lei', 'compra de voto', 'ministério público']\n",
    "resultados = {\n",
    "    'modeloBinario' : [],\n",
    "    'tf' : [],\n",
    "    'idf' : [],\n",
    "    'bm25' : []\n",
    "}\n",
    "\n",
    "for query in queries:\n",
    "    termos = query.split()\n",
    "    resultados['modeloBinario'].append(str(modeloBinario(termos)))\n",
    "    resultados['tf'].append(str(modeloTF(termos)))\n",
    "    resultados['idf'].append(str(modeloIDF(termos)))\n",
    "    resultados['bm25'].append(str(modeloBM25(termos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n",
      "0.96\n",
      "0.8699999999999999\n",
      "0.8620000000000001\n"
     ]
    }
   ],
   "source": [
    "gabarito = pd.read_csv('gabarito.csv')\n",
    "\n",
    "print(mapk(gabarito.busca_binaria, resultados['modeloBinario'], k = 5))\n",
    "print(mapk(gabarito.tf, resultados['tf'], k = 5))\n",
    "print(mapk(gabarito.tfidf, resultados['idf'], k = 5))\n",
    "print(mapk(gabarito.bm25, resultados['bm25'], k = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando o resultado dos modelos juntamente com o gabarito, é possível perceber que a implementação obteve um grande nível de acuracia com o gabarito.\n",
    "Observando o resultado por modelo, vemos que o TF e o Binário possuem a maior nota. Isso deve-se ao fato de que ambos os modelos não possuem um rankeamento complexo.\n",
    "O BM25, por exemplo, pode ter o resultado variado de acordo com o parâmetro k passado, e isso pode influenciar no resultado.\n",
    "\n",
    "É importante ressaltar que o modelo TF obteve uma classificação tão boa devido ao escopo do nosso índice. Como não temos ma grande quantidade de documentos, a quantidade de documentos em que o termo apareceu não causa grande impacto nos resultados, porém é esperado que em grandes conjuntos de dados esse valor afete (melhore) a qualidade dos resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
